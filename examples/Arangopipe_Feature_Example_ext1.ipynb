{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/arangoml/arangopipe/blob/master/examples/Arangopipe_Feature_Example_ext1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation Pre-requisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install python-arango\n",
    "!pip install arangopipe==0.0.6.9.0\n",
    "!pip install pandas PyYAML==5.1.1 sklearn2\n",
    "!pip install jsonpickle\n",
    "!pip install seaborn\n",
    "!pip install dtreeviz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data_url = \"https://raw.githubusercontent.com/arangoml/arangopipe/arangopipe_examples/examples/data/cal_housing.csv\"\n",
    "df = pd.read_csv(data_url, error_bad_lines=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bias Variance Decompostion of Model Estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bootstrapping is used to estimate the bias of the regression model developed earlier. The bias tells us if the model suffers from systematically overestimating or underestimating at certain regions of the dataset. To illustrate the procedure, a sample of the dataset is used. It just takes longer to run the procedure on the full dataset. For details of the theory, please see:\n",
    "\n",
    "\n",
    "1. [Section 2.2, Cosma Shalizi](https://www.stat.cmu.edu/~cshalizi/402/lectures/08-bootstrap/lecture-08.pdf)\n",
    "2. [Tom Dietrich's lecture notes](https://web.engr.oregonstate.edu/~tgd/classes/534/slides/part9.pdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "df['medianHouseValue'] = df['medianHouseValue'].apply(np.log)\n",
    "preds = df.columns.tolist()\n",
    "preds.remove('medianHouseValue')\n",
    "SAMPLE_SIZE = 1000\n",
    "df = df.sample(n = SAMPLE_SIZE)\n",
    "df = df.reset_index()\n",
    "\n",
    "NUM_BOOTSTRAPS = 30\n",
    "BOOTSTRAP_SAMPLE_SIZE =  df.shape[0] - 1\n",
    "bootstrap_Yest = {i : list() for i in range(df.shape[0])}\n",
    "for index in range(df.shape[0]):\n",
    "    for bootrap_iteration in range(NUM_BOOTSTRAPS):\n",
    "        dfi = df.iloc[index, :]\n",
    "        dfb = df.sample(n = BOOTSTRAP_SAMPLE_SIZE, replace=True)\n",
    "        dfb = dfb.append(dfi)\n",
    "        X = dfb[preds].values\n",
    "        Y = dfb['medianHouseValue']\n",
    "\n",
    "        clf = linear_model.Lasso(alpha=0.001, max_iter = 10000)\n",
    "        clf.fit(X, Y)\n",
    "        est_point = X[index, :].reshape(1, -1)\n",
    "        est_at_index = clf.predict(est_point)\n",
    "        bootstrap_Yest[index].append(est_at_index)\n",
    "        \n",
    "    if index % 100 == 0:\n",
    "        print('Completed estimating %4d points in the dataset' % (index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xm = df[preds].values\n",
    "Ym = df['medianHouseValue'].values\n",
    "clf_0 = linear_model.Lasso(alpha=0.001, max_iter = 10000)\n",
    "clf_0.fit(Xm, Ym)\n",
    "Yhat_m = clf_0.predict(Xm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating the Bias at each point in the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see section 2.2 from https://www.stat.cmu.edu/~cshalizi/402/lectures/08-bootstrap/lecture-08.pdf\n",
    "# see https://web.engr.oregonstate.edu/~tgd/classes/534/slides/part9.pdf\n",
    "Expval_at_i = { i : np.mean(np.array(bootstrap_Yest[i])) for i in range(df.shape[0])}\n",
    "bias_at_i = {i : Expval_at_i[i] - Yhat_m[i] for i in range(df.shape[0])}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of the Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "bias_values = [bias for (pt, bias) in bias_at_i.items()]\n",
    "sns.kdeplot(bias_values)\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine a Kernel Density plot of the bias to see the range of values. \n",
    "\n",
    "Note:\n",
    "The response is log transformed, so the bias must be exponeniated to get the real difference from the true value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "cluster_labels = KMeans(n_clusters=5, random_state=0).fit_predict(Xm)\n",
    "cluster_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see where the model is making mistakes, we cluster the (sample of the) dataset and compute the average bias for each cluster. This provides insights into regions of the data space we are doing well (bias close to zero) and regions where we are not doing well. The table below shows the mean cluster bias and the size of the cluster. We see two large clusters where the bias is close to zero (cluster 0 and cluster 1). We see one outlier with a large error (cluster 3). Clusters 1 and 4 are also seem like outliers and need further analysis. This exercise illustrates how we can examine our model's characteristics. We can now link this model analysis activity to our project using Arangopipe.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bias = pd.DataFrame(Xm)\n",
    "df_bias['cluster'] = cluster_labels\n",
    "df_bias['bias'] = bias_values\n",
    "df_bias.groupby('cluster')['bias'].agg([np.mean, np.size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arangopipe.arangopipe_storage.arangopipe_api import ArangoPipe\n",
    "from arangopipe.arangopipe_storage.arangopipe_admin_api import ArangoPipeAdmin\n",
    "from arangopipe.arangopipe_storage.arangopipe_config import ArangoPipeConfig\n",
    "from arangopipe.arangopipe_storage.managed_service_conn_parameters import ManagedServiceConnParam\n",
    "mdb_config = ArangoPipeConfig()\n",
    "msc = ManagedServiceConnParam()\n",
    "conn_params = { msc.DB_SERVICE_HOST : \"arangoml.arangodb.cloud\", \\\n",
    "                        msc.DB_SERVICE_END_POINT : \"createDB\",\\\n",
    "                        msc.DB_SERVICE_NAME : \"createDB\",\\\n",
    "                        msc.DB_SERVICE_PORT : 8529,\\\n",
    "                        msc.DB_CONN_PROTOCOL : 'https'}\n",
    "        \n",
    "mdb_config = mdb_config.create_connection_config(conn_params)\n",
    "admin = ArangoPipeAdmin(reuse_connection = False, config = mdb_config)\n",
    "ap_config = admin.get_config()\n",
    "ap = ArangoPipe(config = ap_config)\n",
    "proj_info = {\"name\": \"Housing_Price_Estimation_Project\"}\n",
    "proj_reg = admin.register_project(proj_info)\n",
    "ds_info = {\"name\" : \"california-housing-dataset\",\\\n",
    "            \"description\": \"This dataset lists median house prices in Califoria. Various house features are provided\",\\\n",
    "           \"source\": \"UCI ML Repository\" }\n",
    "ds_reg = ap.register_dataset(ds_info)\n",
    "import numpy as np\n",
    "df[\"medianHouseValue\"] = df[\"medianHouseValue\"].apply(lambda x: np.log(x))\n",
    "featureset = df.dtypes.to_dict()\n",
    "featureset = {k:str(featureset[k]) for k in featureset}\n",
    "featureset[\"name\"] = \"log_transformed_median_house_value\"\n",
    "fs_reg = ap.register_featureset(featureset, ds_reg[\"_key\"]) #\n",
    "model_info = {\"name\": \"Bias Variance Analysis of LASSO model\",  \"task\": \"Model Validation\"}\n",
    "model_reg = ap.register_model(model_info, project = \"Housing_Price_Estimation_Project\")\n",
    "import uuid\n",
    "import datetime\n",
    "import jsonpickle\n",
    "\n",
    "ruuid = str(uuid.uuid4().int)\n",
    "model_perf = {'model_bias': bias_at_i, 'run_id': ruuid, \"timestamp\": str(datetime.datetime.now())}\n",
    "\n",
    "mp = clf.get_params()\n",
    "mp = jsonpickle.encode(mp)\n",
    "model_params = {'run_id': ruuid, 'model_params': mp}\n",
    "\n",
    "run_info = {\"dataset\" : ds_reg[\"_key\"],\\\n",
    "                    \"featureset\": fs_reg[\"_key\"],\\\n",
    "                    \"run_id\": ruuid,\\\n",
    "                    \"model\": model_reg[\"_key\"],\\\n",
    "                    \"model-params\": model_params,\\\n",
    "                    \"model-perf\": model_perf,\\\n",
    "                    \"tag\": \"Housing-Price-Hyperopt-Experiment\",\\\n",
    "                    \"project\": \"Housing Price Estimation Project\"}\n",
    "ap.log_run(run_info)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
